---
title: '6372: Project 1'
author: "Megan Ball, Matt Farrow, Neddy Nyatome"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
library(corrplot)
library(GGally)
library(gt)
library(hrbrthemes)
library(car)
library(leaps)
# library(knitr)
# library(scales)
```

## Introduction

## Data Description

Description and context of the Life Expectancy (WHO) dataset can be found [here](https://www.kaggle.com/kumarajarshi/life-expectancy-who).

```{r load-data}
# Load data
df <- read_csv(here::here("data - raw", "Life Expectancy Data.csv"))

# Clean up column names
df_clean <- janitor::clean_names(df)

# Look at the data
glimpse(df_clean)
```

## Exploratory Data Analysis

### Examing the Data

```{r echo=FALSE}
df_clean %>% 
  ggplot(aes(life_expectancy)) +
  geom_histogram(fill = "steelblue", color = "black") +
  labs(title = "Histogram of Life Expectancy",
       x = "Age",
       y = "Count") +
  theme_ipsum()

df_clean %>% 
  ggplot(aes(sample = life_expectancy)) +
  geom_qq(pch = 21, size = 3, na.rm = TRUE) +
  geom_qq_line(color = "indianred", na.rm = TRUE) +
  labs(title = "Quantile-Quantile Plot of Life Expectancy",
       x = "Theoretical",
       y = "Sample") +
  theme_ipsum()
```

### Convert to Factors

Before we get started, we'll convert the qualitative variables `country` and `status` to factors. 
```{r convert-to-factor}
df_clean$country <- as_factor(df_clean$country)
df_clean$status  <- as_factor(df_clean$status)
```

### Check for Correlation

```{r message=FALSE, warning=FALSE}
ggcorr(
  df_clean,
  label = TRUE,
  label_alpha = TRUE,
  label_size = 3,
  layout.exp = 2,
  cex = 3.5,
  hjust = 1
)
```

We examined various correlation matrices to determine whether there were variable(s) that should be addressed. We'll start by removing redundant variables and picking ones with fewer `NA` values.

```{r}
df_clean %>% 
  select(-c(under_five_deaths, gdp, thinness_1_19_years)) %>% 
  ggcorr(
  label = TRUE,
  label_alpha = TRUE,
  label_size = 3,
  layout.exp = 2,
  cex = 3.5,
  hjust = 1
)
```

Let's now look at what happens when we also remove `population`, since it has minimal correlation to `life_expectancy`.

```{r}
df_clean %>% 
  select(-c(under_five_deaths, gdp, thinness_1_19_years, population)) %>% 
  ggcorr(
  label = TRUE,
  label_alpha = TRUE,
  label_size = 3,
  layout.exp = 2,
  cex = 3.5,
  hjust = 1
)
```

We'll proceed, dropping the columns we've looked at.

```{r}
df_clean <- df_clean %>% 
  select(-c(under_five_deaths, gdp, thinness_1_19_years, population))
```

### Deal with Missing Values

```{r}
# Check for missing values
tibble(variable = names(colSums(is.na(df_clean))),
       missing = colSums(is.na(df_clean))) %>% 
  gt()

# Drop all rows where life expectancy is NA
df_clean <- df_clean %>% 
  filter(!is.na(life_expectancy))

# Recheck missing value counts
tibble(variable = names(colSums(is.na(df_clean))),
       missing = colSums(is.na(df_clean))) %>% 
  gt()

# Drop remaining rows with NA's for the interpretable model
# Remove all rows with an NA
df_interp <- na.omit(df_clean)

# Final check of missing values
tibble(variable = names(colSums(is.na(df_interp))),
       missing = colSums(is.na(df_interp))) %>% 
  gt()
```

### Analysis of Years

Now that we've subsetted our variables and dealt with `NA`'s, let's look at how many records we now have by year.

```{r}
df_interp %>% count(year)
```

Our feature engineering dropped a number of records from 2000 and 2001, and almost all of the records from 2015. Let's go with the most recent "good" sample size (2011-2014).

```{r}
df_interp <- df_interp %>% filter(year %in% 2011:2014)
```

## Build the Model

Now that we've finished our feature engineering, let's start building our interpretable model. 

```{r}
# Set the maximum number of variables to consider in the model. Although the
# model can handle up to 20, the more we add, the less interpretable the final
# model will be.
consider <- 18

# Fit the model. We'll remove country, but keep it in the data set for
# interpretation.
regfit_full <-
  regsubsets(life_expectancy ~ .,
             df_interp[, -1],
             nvmax = consider)

# Examine the regression summary
reg_summary <- summary(regfit_full)

# Look at the names of reg_summary
names(reg_summary)

# What are the R-squared values?
reg_summary$rsq

# Plot RSS, adjusted $R^2$ $C_p$ and BIC for all models
par(mfrow = c(2, 2))
plot(reg_summary$rss,
     xlab = "Number of Variables",
     ylab = "RSS",
     type = "l")
plot(reg_summary$adjr2,
     xlab = "Number of Variables",
     ylab = "Adjusted RSq",
     type = "l")
points(
  consider,
  reg_summary$adjr2[which.max(reg_summary$adjr2)],
  col = "red",
  cex = 2,
  pch = 20
)
plot(reg_summary$cp,
     xlab = "Number of Variables",
     ylab = "Cp",
     type = "l")
points(
  consider,
  reg_summary$cp[which.min(reg_summary$cp)],
  col = "red",
  cex = 2,
  pch = 20
)
plot(reg_summary$bic,
     xlab = "Number of Variables",
     ylab = "BIC",
     type = "l")
points(
  consider,
  reg_summary$bic[which.min(reg_summary$bic)],
  col = "red",
  cex = 2,
  pch = 20
)

# Display the selected variables for the best model with a given number of
# predictors
plot(regfit_full, scale = "r2")
plot(regfit_full, scale = "adjr2")
plot(regfit_full, scale = "Cp")
plot(regfit_full, scale = "bic")
```

The model with the lowest BIC is the five-variable model that contains `adult_mortality`, `percentage_expenditure`, `total_expenditure`, `hiv_aids`, and `income_composition_of_resources`. We can use the coef() function to see the coefficient estimates associated with this model.

```{r}
coef(regfit_full, 5)
```

### Run Forward and Backward Stepwise Selection

```{r}
# Forward
regfit_fwd <-
  regsubsets(life_expectancy ~ ., data = df_interp[, -1], method = "forward")
summary(regfit_fwd)

# Backward
regfit_bwd <-
  regsubsets(life_expectancy ~ ., data = df_interp[, -1], method = "backward")
summary(regfit_bwd)

# Compare coefficients
tibble(variables = names(coef(regfit_full, 5)),
       full = coef(regfit_full, 5),
       fwd = coef(regfit_fwd, 5),
       bwd = coef(regfit_bwd, 5)) %>% 
  gt()
```

### Choose Using Validation Set and Cross Validation

```{r}
# Set seed
set.seed(1)

# Build test and training data sets, dropping country from regfit_best &
# test_mat because I was getting a warning that 1 linear dependencies found
train <- sample(c(TRUE, FALSE), nrow(df_interp), rep = TRUE)
test <- (!train)
regfit_best <- regsubsets(life_expectancy ~ ., data = df_interp[train, -1])
test_mat <- model.matrix(life_expectancy ~ ., data = df_interp[test, -1])

# Run a loop, and for each size `i`, extract the coefficients from `regfit_best`
# for the best model of that size, multiply them into the appropriate columns of
# the test model matric to form the predictions, and compute the test MSE.
val_errors <- rep(NA, consider)
for (i in 1:consider) {
  coefi <- coef(regfit_best, id = i)
  pred <- test_mat[, names(coefi)] %*% coefi
  val_errors[i] <- mean((df_interp$life_expectancy[test] - pred)^2)
}

# Find the best model
val_errors
coef(regfit_best, which.min(val_errors))

# Write a prediction fuction
predict_regsubsets <- function(object, newdata, id, ...) {
  form <- as.formula(object$call[[2]])
  mat <- model.matrix(form, newdata)
  coefi <- coef(object, id = id)
  xvars <- names(coefi)
  mat[, xvars] %*% coefi
}

# Perform best subset selection on the full data set, and select the best model.
regfit_best <- regsubsets(life_expectancy ~ ., data = df_interp[,-1])
coef(regfit_best, which.min(val_errors))

# Use cross-validation to choose among models
k <- 10
set.seed(1)
folds <- sample(1:k, nrow(df_interp), replace = TRUE)
cv_errors <- matrix(NA, k, consider, dimnames = list(NULL, paste(1:consider)))

predict_regsubsets <- function(object, newdata, id, ...) {
  form <- as.formula(object$call[[2]])
  mat <- model.matrix(form, newdata)
  coefi <- coef(object, id = id)
  mat[, names(coefi)] %*% coefi
}

# Perform cross-validation
for (j in 1:k) {
  best_fit <-
    regsubsets(life_expectancy ~ ., data = df_interp[folds != j, -1], nvmax = consider)
  for (i in 1:16) {
    pred <- predict(best_fit, df_interp[folds == j, -1], id = i)
    cv_errors[j, i] <-
      mean((df_interp$life_expectancy[folds == j] - pred) ^ 2)
  }
}

# Use the apply function to average over the columns of the matrix in order to
# obtain a vector for which the jth element is the cross-validation error for
# the j-variable model.
mean_cv_errors <- apply(cv_errors, 2, mean)
mean_cv_errors
par(mfrow = c(1, 1))
plot(mean_cv_errors, type = "b")

# Perform best subset selection on the full data set in order to obtain the
# variables for the final model
reg_best <- regsubsets(life_expectancy ~ ., data = df_interp[, -1])
coef(reg_best, 4)  # the number sets the number of variables we want

# Build the final model using the best subset selection results
final_model <-
  lm(
    life_expectancy ~ adult_mortality +
      total_expenditure +
      hiv_aids +
      income_composition_of_resources,
    data = df_interp
)

# Final model summary
summary(final_model)

#check diagnostics
par(mfrow = c(1, 1))
plot(
  final_model$fitted.values,
  df_interp$life_expectancy,
  xlab = "Predicted",
  ylab = "Life Expectancy"
)
lines(c(0, 90), c(0, 90), col = "red")

par(mfrow=c(2,2))
plot(final_model)

######################################################
###Now let's proceed with just the best model overall###
#########################################################

# Fit a model on our df_interp data set
par(mfrow = c(1, 2))
test.model <- lm(life_expectancy ~ ., df_interp[, -1])
plot(test.model$fitted.values,
     test.model$residuals,
     xlab = "Fitted Values",
     ylab = "Residuals")
plot(df_interp$life_expectancy,
     test.model$residuals,
     xlab = "Life Expectancy",
     ylab = "Residuals")


###How do you do lasso etc and CV?????????

```




## Objective 1

### Restatement of Problem and the Overall Approach to Solve It

### Model Selection

#### Type of Selection

- LASSO
- RIDGE
- ELASTIC NET
- Stepwise
- Forward
- Backward
- Manual / Intuition
- A mix of all of the above

#### Checking Assumptions

- Residual Plots
- Influential point analysis (Cook’s D and Leverage)

#### Compare Competing Models

Via:  Training and test set split or CV
Possible Metrics: ASE (Required), AIC, BIC, adj R2, are all welcome additions
	
#### Parameter Interpretation (Simple model only)

- Interpretation 
- Confidence Intervals

#### Additional Details on a more complicated regression model 

## Objective 2 Deliverable (see above)
	
Final conclusions from the analyses of Objective 1’s interpretable model and include comments on what model would be recommended if prediction was the only goal (comparing all models considered).  

## Appendix 

- Well-commented SAS/R Code
- Graphics and summary tables (Can be placed in the appendix or in the written report itself.)
